<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="EasyTalk">
  <meta name="keywords" content="EasyTalk">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>EasyTalk (AAAI #4987)</title>

  <style>
    td {
        padding: 10px;
        border: 10px solid rgb(255, 255, 255);
    }
    section {
      margin: 0;
      padding: 0;
    }
    section {
      margin-bottom: -20px; /* 减小间距 */
    }
    video {
      margin-top: -20px; /* 减小间距 */
      margin-bottom: -20px; /* 减小间距 */
    }
    section:last-child {
      margin-bottom: 0; /* 最后一个section不减小间距 */
    }
</style>

<!--   Global site tag (gtag.js) - Google Analytics-->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-Y5ZVQZ7NHC"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-Y5ZVQZ7NHC');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

<link rel="apple-touch-icon-precomposed" sizes="120x120" href="./img/github-6980894_1280.png">
<link rel="icon" href="./img/github-6980894_1280.png" type="image/x-icon"/>
<link rel="shortcut icon" href="./img/github-6980894_1280.png" type="image/x-icon"/>

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>



</head>
<body>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">EasyTalk: Cross-Modal Style Alignment for Emotional Talking Head Generation</h1>

          <div class="is-size-3 publication-authors">
            <span class="author-block"> </span>
            <span class="author-block"> 
              <h2 class="subtitle has-text-centered" style="font-size: 2.4rem; color: #29d4d2">
              AAAI 2025 Anonymous Submission #4987 </span>
            </h2>
          </div>

        </div>
      </div>
    </div>
  </div>
</section>

<!--teaser-->
<section class="hero teaser is-small">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <h2 class="subtitle has-text-centered" style="font-size: 1.38rem; color: #1c1c1c">
        We present <span style="color: #2fd3fc"><b>EasyTalk</b></span>,
        <p>
        a cross-modal style controllable emotional talking head generation method.
      </h2>
    </div>
  </div>
</section>

<!--Abstract-->
<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Speech-driven talking head generation has became a trending topic recently. However, expressing emotion on generated talking heads is still challenging due to the heterogeneity of different modals that are required to be handled properly during the generation. To enable effective facial expression control when generating talking heads, we propose the <b><u>EasyTalk</u></b>, a two-stage generation framework supporting the control of facial expression by emotion signals from images, text, or speech. Specifically, we separate the generation approach into two stages: Speech-to-Motion and Motion-to-Video, leveraging ARKit coefficients as the intermediate representations. We propose to utilize visemes as emotion-invariant representations to guide lip movements, thereby compelling the model to learn expression-related motions from the emotion inputs. We further align emotional signals from different modalities by cross-modal contrastive learning for more effective control. Extensive experiments show that our method achieves new state-of-the-art measured by lip-sync and realistic metrics and enables efficient facial expression controls.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
  </div>
</section>

<!-- Methodology -->
<section class="hero is-light is-small">
  <div class="container is-max-desktop">
    <div class="hero-body">
        <!--/ Methodology. -->
        <div class="section-title">
          <h2 class="title is-3 is-centered">Methodology</h2>
        </div>
        <div class="columns is-centered has-text-centered">
          <div class="column">
            <div class="publication-img">
              <img id="architecture" src="./assets/img/main.jpg"/>
            </div>
          </div>
        </div>
        <p>
          Illustration of the proposed model.
        </p>
    </div>
  </div>
</section>

<!-- Showcases -->
<section class="section">
  <div class="container is-max-desktop">

      <div class="section-title">
        <h2 class="title is-3">Showcases</h2>
      </div>

    <h3 class="title is-4">Audio-Driven (without expressions)</h3>
    <p>
      Audio driven cases without multi-modal style control.
    </p>
    <table style="border-collapse:separate; border-spacing:0px 10px;">
    <tr>
      <td width="50%"> <video id="showcases1" controls="" playsinline="" height="90%">
        <source src="./assets/video/test.mp4" type="video/mp4">
      </video> </td>
      <td width="50%"> <video id="showcases1" controls="" playsinline="" height="90%">
        <source src="./assets/video/test.mp4" type="video/mp4">
      </video> </td>
    </tr>
    </table>

    <br><br>
    <h3 class="title is-4">Multi-modal Style Control</h3>
    <table style="border-collapse:separate; border-spacing:0px 10px;">
    <tr>
      <td width="50%"> <video id="showcases1" controls="" playsinline="" height="90%">
        <source src="./assets/video/test.mp4" type="video/mp4">
      </video> </td>
      <td width="50%"> <video id="showcases1" controls="" playsinline="" height="90%">
        <source src="./assets/video/test.mp4" type="video/mp4">
      </video> </td>
    </tr>
    </table>

  </div>
</section>

<!-- Baseline compare -->
<section class="section">
  <div class="container is-max-desktop">

      <div class="section-title">
        <h2 class="title is-3">Comparison With Current Methods</h2>
      </div>

    <div class="columns is-centered">
      <div class="column">
        <div class="content">
          <div class="columns is-vcentered interpolation-panel">
            <div class="column has-text-centered">
              <img src="./assets/img/methods.png"  width="55%">
              <p>Audio-driven talking head video generation methods to be compared.</p>
            </div>
          </div>
        </div>
      </div>

    </div>
    <h3 class="title is-4">Qualitative Evaluation</h3>
    <video id="matting-video" controls="" playsinline="" height="100%">
      <source src="./assets/video/test.mp4" type="video/mp4">
    </video>

    <br><br>
    <h3 class="title is-4">Quantitative Evaluation</h3>
    <div class="columns is-vcentered interpolation-panel">
      <div class="column has-text-centered">
        <img src="./assets/img/metric.png">
        <p> The quantitative results on dataset A and B.</p>
      </div>
    </div>

    <br><br>
    <h3 class="title is-4">User Study</h3>
    <div class="columns is-vcentered interpolation-panel">
      <div class="column has-text-centered">
        <img src="./assets/img/metric.png">
        <p> User study results.</p>
      </div>
    </div>

  </div>
</section>

<!-- Ablation Studies -->
<section class="section">
  <div class="container is-max-desktop">

      <div class="section-title">
        <h2 class="title is-3">Ablation Studies</h2>
      </div>

    <h3 class="title is-4">1</h3>
    <video id="matting-video" controls="" playsinline="" height="100%">
      <source src="./assets/video/test.mp4" type="video/mp4">
    </video>

  </div>
</section>

<section class="section hero is-light">
  <div class="container is-max-desktop">
      <h1 class="title is-4">
          Ethical Consideration (Copied from AniTalker)
      </h1>
      <div class="content has-text-justified-desktop">
          <p>

          The potential misuse of lifelike digital human face generation, such as for creating fraudulent identities or disseminating misinformation, necessitates preemptive ethical measures. Before utilizing these models, it is crucial for organizations to integrate ethical guidelines into their policies, ensuring the application of this technology emphasizes consent, transparency, and accountability. Furthermore, it is recommended to embed visible or invisible digital watermarks in any generated content.

          </p>

      </div>

      <h1 class="title is-4">
          Removal Policy
      </h1>
      <div class="content has-text-justified-desktop">

           <p>

         Please be aware that all videos on this page are algorithmically generated from publicly available sources and are intended solely for academic demonstrations and algorithm comparisons.  Any other form of usage is prohibited. Besides, if required by the original image owner or in the case of misuse of the models, the images, models, and codes associated with this project may be removed at any time.
          </p>
      </div>
  </div>
</section>

<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website source code is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            Website source code based on the <a href="https://nerfies.github.io/"> Nerfies</a> project page. If you want to reuse their <a
              href="https://github.com/nerfies/nerfies.github.io">source code</a>, please credit them appropriately.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
